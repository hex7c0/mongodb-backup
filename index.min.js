"use strict";

function error(err) {
    return logger(err.message);
}

function writeMetadata(collection, metadata, next) {
    return collection.indexes(function(err, indexes) {
        return err ? (error(err), next(null)) : void fs.writeFile(metadata + collection.collectionName, JSON.stringify(indexes), next);
    });
}

function makeDir(path, next) {
    return fs.stat(path, function(err, stats) {
        return err && "ENOENT" === err.code ? (logger("make dir at " + path), fs.mkdir(path, function(err) {
            return next(err, path);
        })) : stats && stats.isDirectory() === !1 ? (logger("unlink file at " + path), fs.unlink(path, function() {
            return logger("make dir at " + path), fs.mkdir(path, function(err) {
                return next(err, path);
            });
        })) : next(null, path);
    });
}

function rmDir(path, next) {
    return fs.readdirSync(path).forEach(function(first) {
        var database = path + first;
        if (fs.statSync(database).isDirectory() !== !1) {
            var metadata = "", collections = fs.readdirSync(database);
            return fs.existsSync(database + "/.metadata") === !0 && (metadata = database + "/.metadata/", 
            delete collections[collections.indexOf(".metadata")]), collections.forEach(function(second) {
                var collection = database + "/" + second;
                if (fs.statSync(collection).isDirectory() !== !1) return fs.readdirSync(collection).forEach(function(third) {
                    var document = collection + "/" + third;
                    return fs.unlinkSync(document), next ? next(null, document) : "";
                }), "" !== metadata && fs.unlinkSync(metadata + second), fs.rmdirSync(collection);
            }), "" !== metadata && fs.rmdirSync(metadata), fs.rmdirSync(database);
        }
    });
}

function toJsonAsync(doc, collectionPath) {
    fs.writeFile(collectionPath + doc._id + ".json", JSON.stringify(doc));
}

function toBsonAsync(doc, collectionPath) {
    fs.writeFile(collectionPath + doc._id + ".bson", BSON.serialize(doc));
}

function allCollections(db, name, query, metadata, parser, next) {
    return db.collections(function(err, collections) {
        if (err) return error(err);
        var last = collections.length, index = 0;
        return 1 > last ? next(null) : collections.forEach(function(collection) {
            return systemRegex.test(collection.collectionName) === !0 ? last === ++index ? next(null) : null : (logger("select collection " + collection.collectionName), 
            makeDir(name + collection.collectionName + "/", function(err, name) {
                return meta(collection, metadata, function() {
                    var stream = collection.find(query).snapshot(!0).stream();
                    stream.once("end", function() {
                        return last === ++index ? next(null) : null;
                    }).on("data", function(doc) {
                        parser(doc, name);
                    });
                });
            }));
        });
    });
}

function allCollectionsScan(db, name, numCursors, metadata, parser, next) {
    return db.collections(function(err, collections) {
        if (err) return error(err);
        var last = collections.length, index = 0;
        return 1 > last ? next(null) : collections.forEach(function(collection) {
            return systemRegex.test(collection.collectionName) === !0 ? last === ++index ? next(null) : null : (logger("select collection scan " + collection.collectionName), 
            makeDir(name + collection.collectionName + "/", function(err, name) {
                return meta(collection, metadata, function() {
                    return collection.parallelCollectionScan({
                        numCursors: numCursors
                    }, function(err, cursors) {
                        var ii, cursorsDone;
                        if (ii = cursorsDone = cursors.length, 0 === ii) return last === ++index ? next(null) : null;
                        for (var i = 0; ii > i; ++i) cursors[i].once("end", function() {
                            return 0 === --cursorsDone ? last === ++index ? next(null) : null : void 0;
                        }).on("data", function(doc) {
                            parser(doc, name);
                        });
                    });
                });
            }));
        });
    });
}

function someCollections(db, name, query, metadata, parser, next, collections) {
    var last = collections.length, index = 0;
    return 1 > last ? next(null) : collections.forEach(function(collection) {
        return db.collection(collection, function(err, collection) {
            return logger("select collection " + collection.collectionName), err ? last === ++index ? next(err) : error(err) : makeDir(name + collection.collectionName + "/", function(err, name) {
                return meta(collection, metadata, function() {
                    var stream = collection.find(query).snapshot(!0).stream();
                    stream.once("end", function() {
                        return last === ++index ? next(null) : null;
                    }).on("data", function(doc) {
                        parser(doc, name);
                    });
                });
            });
        });
    });
}

function someCollectionsScan(db, name, numCursors, metadata, parser, next, collections) {
    var last = collections.length, index = 0;
    return 1 > last ? next(null) : collections.forEach(function(collection) {
        return db.collection(collection, function(err, collection) {
            return logger("select collection scan " + collection.collectionName), err ? last === ++index ? next(err) : error(err) : makeDir(name + collection.collectionName + "/", function(err, name) {
                return meta(collection, metadata, function() {
                    return collection.parallelCollectionScan({
                        numCursors: numCursors
                    }, function(err, cursors) {
                        var ii, cursorsDone;
                        if (ii = cursorsDone = cursors.length, 0 === ii) return last === ++index ? next(null) : null;
                        for (var i = 0; ii > i; ++i) cursors[i].once("end", function() {
                            return 0 === --cursorsDone ? last === ++index ? next(null) : null : void 0;
                        }).on("data", function(doc) {
                            parser(doc, name);
                        });
                    });
                });
            });
        });
    });
}

function wrapper(my) {
    function callback() {
        logger("backup stop"), null !== my.callback && (logger("callback run"), my.callback());
    }
    var parser;
    if ("function" == typeof my.parser) parser = my.parser; else switch (my.parser) {
      case "bson":
        BSON = require("bson"), BSON = new BSON.BSONPure.BSON(), parser = toBsonAsync;
        break;

      case "json":
        parser = toJsonAsync;
        break;

      default:
        throw new Error("missing parser option");
    }
    var discriminator = allCollections;
    if (null !== my.collections ? (discriminator = someCollections, my.numCursors && (discriminator = someCollectionsScan, 
    my.query = my.numCursors)) : my.numCursors && (discriminator = allCollectionsScan, 
    my.query = my.numCursors), null === my.logger) logger = function() {}; else {
        logger = require("logger-request")({
            filename: my.logger,
            standalone: !0,
            winston: {
                logger: "_mongo_b" + my.logger,
                level: "info",
                json: !1
            }
        }), logger("backup start");
        var log = require("mongodb").Logger;
        log.setLevel("info"), log.setCurrentLogger(function(msg) {
            return logger(msg);
        });
    }
    var metadata = "";
    return meta = my.metadata === !0 ? writeMetadata : function(a, b, c) {
        return c();
    }, require("mongodb").MongoClient.connect(my.uri, my.options, function(err, db) {
        if (logger("db open"), err) return error(err);
        var root = null === my.tar ? my.root : my.dir;
        makeDir(root, function(err, name) {
            makeDir(name + db.databaseName + "/", function(err, name) {
                function go() {
                    return discriminator(db, name, my.query, metadata, parser, function(err) {
                        return err && error(err), logger("db close"), db.close(), my.tar ? makeDir(my.root, function(err, name) {
                            err && error(err);
                            var dest;
                            my.stream ? (logger("send tar file to stream"), dest = my.stream) : (logger("make tar file at " + name + my.tar), 
                            dest = fs.createWriteStream(name + my.tar));
                            var packer = require("tar").Pack().on("error", error).on("end", function() {
                                return rmDir(root), callback();
                            });
                            return require("fstream").Reader({
                                path: root + db.databaseName,
                                type: "Directory"
                            }).on("error", error).pipe(packer).pipe(dest);
                        }) : callback();
                    }, my.collections);
                }
                my.metadata === !1 ? go() : (metadata = name + ".metadata/", makeDir(metadata, go));
            });
        });
    });
}

function backup(options) {
    var resolve = require("path").resolve, opt = options || Object.create(null);
    if (!opt.uri) throw new Error("missing uri option");
    if (!opt.stream) {
        if (!opt.root) throw new Error("missing root option");
        if (fs.existsSync(opt.root) && !fs.statSync(opt.root).isDirectory()) throw new Error("root option is not a directory");
    }
    var my = {
        dir: __dirname + "/dump/",
        uri: String(opt.uri),
        root: resolve(String(opt.root || "")) + "/",
        stream: opt.stream || null,
        parser: opt.parser || "bson",
        numCursors: ~~opt.numCursors,
        collections: Array.isArray(opt.collections) ? opt.collections : null,
        callback: "function" == typeof opt.callback ? opt.callback : null,
        tar: "string" == typeof opt.tar ? opt.tar : null,
        query: "object" == typeof opt.query ? opt.query : {},
        logger: "string" == typeof opt.logger ? resolve(opt.logger) : null,
        options: "object" == typeof opt.options ? opt.options : {},
        metadata: Boolean(opt.metadata)
    };
    return my.stream && (my.tar = !0), wrapper(my);
}

var systemRegex = /^system\./, fs = require("fs"), BSON, logger, meta;

module.exports = backup;
